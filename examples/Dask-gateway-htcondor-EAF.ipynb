{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb383578-3078-4972-98f5-7bf9d9ea2f98",
   "metadata": {},
   "source": [
    "## Basic cluster creation\n",
    "* The following code will connect to the Dask Gateway server, use jupyterhub OAuth to authenticate and ask the server for a new cluster.\n",
    "* This willl trigger the server to start a Scheduler pod in OKD, which will be exposed via Traefik. \n",
    "* To connect to the scheduler, use the public route: tls://dask-gateway-tls.fnal.gov:443\n",
    "* This route is static for now. Functionality is being built to expose it dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc15031-ac4a-43d8-b990-0d35b86a9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import pprint\n",
    "import time\n",
    "import socket\n",
    "import dask_gateway\n",
    "from dask_gateway import Gateway\n",
    "\n",
    "# For debugging mostly. these two are used for authenticatng against Jupyter\n",
    "print(os.environ['JUPYTERHUB_API_TOKEN'])\n",
    "print(os.environ['JUPYTERHUB_API_URL'])\n",
    "\n",
    "# These settings are static\n",
    "gateway = Gateway(\n",
    "     address=\"http://172.30.227.32\",\n",
    "     auth='jupyterhub',\n",
    ")\n",
    "\n",
    "# Use cluster = gateway.new_cluster(shutdown_on_close=False) \n",
    "# to keep the cluster running after the client process dies\n",
    "print(\"Creating GatewayCluster, this might take up to 10 seconds\")\n",
    "cluster = gateway.new_cluster()\n",
    "# Enable cluster adaptive scaling\n",
    "#cluster.adapt(minimum=0, maximum=10)\n",
    "# Make sure the cluster exists\n",
    "pprint.pprint(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2346c4a-6602-49b4-8606-6b28c7097eb6",
   "metadata": {},
   "source": [
    "## Staging and htcondor worker submit\n",
    "* In order to have hybrid Dask clusters, we have added a mode of operation to Dask Gateway Server in which external Dask Singularity workers join a containerized Kubernetes scheduler on the fly. \n",
    "* The following code will use the Dask Gateway API to interact with the cluster, obtain information for to configure workers to properly connect and authenticate, and finally join the scheduler in a hybrid cluster.\n",
    "* To connect to the scheduler, we use the public route: tls://dask-gateway-tls.fnal.gov:443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de54c9-7406-45c1-bbea-24ba32ee9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pwd\n",
    "\n",
    "def prepareWorkerJob(cluster, n_workers):\n",
    "    username = pwd.getpwuid( os.getuid() )[ 0 ]\n",
    "    security = cluster.security\n",
    "    tmproot = f\"/uscmst1b_scratch/lpc1/3DayLifetime/{username}/{cluster_name}\"\n",
    "    condor_logdir = f\"{tmproot}/condor\"\n",
    "    credentials_dir = f\"{tmproot}/dask-credentials\"\n",
    "    worker_space_dir = f\"{tmproot}/dask-worker-space\"\n",
    "    image_name = f\"/cvmfs/unpacked.cern.ch/registry.hub.docker.com/coffeateam/coffea-dask-cc7-gateway:0.7.12-fastjet-3.3.4.0rc9-g8a990fa\"\n",
    "    os.makedirs(tmproot, exist_ok=True)\n",
    "    os.makedirs(condor_logdir, exist_ok=True)\n",
    "    os.makedirs(credentials_dir, exist_ok=True)\n",
    "    os.makedirs(worker_space_dir, exist_ok=True)\n",
    "\n",
    "    with open(f\"{credentials_dir}/dask.crt\", 'w') as f:\n",
    "        f.write(security.tls_cert)\n",
    "    with open(f\"{credentials_dir}/dask.pem\", 'w') as f:\n",
    "        f.write(security.tls_key)\n",
    "    with open(f\"{credentials_dir}/api-token\", 'w') as f:\n",
    "        f.write(os.environ['JUPYTERHUB_API_TOKEN'])\n",
    "        \n",
    "    # Prepare JDL\n",
    "    jdl = \"\"\"executable = start.sh\n",
    "arguments = \"\"\"+cluster_name+\"\"\" htcdask-worker_$(Cluster)_$(Process)\n",
    "output = condor/htcdask-worker$(Cluster)_$(Process).out\n",
    "error = condor/htcdask-worker$(Cluster)_$(Process).err\n",
    "log = condor/htcdask-worker$(Cluster)_$(Process).log\n",
    "request_cpus = 4\n",
    "request_memory = 2100\n",
    "should_transfer_files = yes\n",
    "transfer_input_files = \"\"\"+credentials_dir+\"\"\", \"\"\"+worker_space_dir+\"\"\" , \"\"\"+condor_logdir+\"\"\"\n",
    "Queue \"\"\"+str(n_workers)+\"\"\n",
    "    \n",
    "    with open(f\"{tmproot}/htcdask_submitfile.jdl\", 'w+') as f:\n",
    "        f.writelines(jdl)\n",
    "        \n",
    "    # Prepare singularity command\n",
    "    sing = \"\"\"#!/bin/bash\n",
    "export SINGULARITYENV_DASK_GATEWAY_WORKER_NAME=$2\n",
    "export SINGULARITYENV_DASK_GATEWAY_API_URL=\"https://dask-gateway-api.fnal.gov/api\"\n",
    "export SINGULARITYENV_DASK_GATEWAY_CLUSTER_NAME=$1\n",
    "export SINGULARITYENV_DASK_GATEWAY_API_TOKEN=/etc/dask-credentials/api-token\n",
    "export SINGULARITYENV_DASK_DISTRIBUTED__LOGGING__DISTRIBUTED=\"debug\"\n",
    "\n",
    "worker_space_dir=${PWD}/dask-worker-space/$2\n",
    "mkdir $worker_space_dir\n",
    "\n",
    "singularity exec -B ${worker_space_dir}:/srv/dask-worker-space -B dask-credentials:/etc/dask-credentials /cvmfs/unpacked.cern.ch/registry.hub.docker.com/coffeateam/coffea-dask-cc7-gateway:0.7.12-fastjet-3.3.4.0rc9-g8a990fa \\\n",
    "dask-worker --name $2 --tls-ca-file /etc/dask-credentials/dask.crt --tls-cert /etc/dask-credentials/dask.crt --tls-key /etc/dask-credentials/dask.pem --worker-port 10000:10070 --no-nanny --no-dashboard --local-directory /srv --nthreads 1 --nprocs 1 tls://dask-gateway-tls.fnal.gov:443\"\"\"\n",
    "    \n",
    "    with open(f\"{tmproot}/start.sh\", 'w+') as f:\n",
    "        f.writelines(sing)\n",
    "    os.chmod(f\"{tmproot}/start.sh\", 0o775)\n",
    "    return tmproot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078081b4-2937-4940-8df2-1120d3380db7",
   "metadata": {},
   "source": [
    "## Scaling up\n",
    "* Inform the GatewayServer that the cluster will scale to `n_workers`\n",
    "* Call the function to stage all relevant files and scripts for HTCondor Dask Workers\n",
    "* Call `condor_submit` from the command line, to avoid disrupting existing condor wrappers installed by T1 admins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c8b8b-128d-4c5c-9643-f9c60ee33e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = cluster.name\n",
    "n_workers = 1\n",
    "\n",
    "cluster.scale(n_workers)\n",
    "print(\"Staging \"+str(n_workers)+\" batch workers for cluster: \"+cluster_name)\n",
    "\n",
    "tmproot = prepareWorkerJob(cluster,n_workers)\n",
    "print(\"Sandbox folder located at: \"+tmproot)\n",
    "\n",
    "print(\"Submitting HTCondor job(s) for \"+str(n_workers)+\" workers\")\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# We add this to avoid a bug on Farruk's condor_submit wrapper (a fix is in progress)\n",
    "os.environ['LS_COLORS']=\"ExGxBxDxCxEgEdxbxgxcxd\"\n",
    "\n",
    "# Submit our jdl, print the result and call the cluster widget\n",
    "result = subprocess.check_output(['sh','-c','/usr/local/bin/condor_submit htcdask_submitfile.jdl'], cwd=tmproot)\n",
    "pprint.pprint(result)\n",
    "\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb0c19-56ec-43d0-9f78-da220709f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a client for connecting to your cluster scheduler\n",
    "# Your cluster should be ready to take requests\n",
    "cluster = gateway.connect(cluster.name)\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e56f7d-970e-4218-b2f4-2ed57c75c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run computations on the cluster\n",
    "# At this point you should be able to use normal dask methods to do work.\n",
    "# For example, here we take the mean of a random array.\n",
    "import dask.array as da\n",
    "a = da.random.normal(size=(1000, 1000), chunks=(500, 500))\n",
    "a.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01837e8b-eaba-4361-9de2-2eabf0fc637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell to remove/shutdown the cluster\n",
    "cluster = gateway.connect(cluster.name)\n",
    "cluster\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
